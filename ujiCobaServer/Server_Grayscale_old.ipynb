{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "\n",
    "\n",
    "# Import konfigurasi dari file config.py\n",
    "from config.config_aio import AIO_SERVER, AIO_USERNAME, AIO_KEY, AIO_FEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inisialisasi Firebase\n",
    "# cred = credentials.Certificate('firebase_sdk_admin_led_switch.json')\n",
    "# firebase_admin.initialize_app(cred, {\n",
    "#     'databaseURL': 'https://led-switch-6c690-default-rtdb.firebaseio.com'  # Ganti dengan URL Realtime Database Anda\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "# Adafruit IO Configuration\n",
    "\n",
    "# Gunakan konfigurasi dalam kode Anda\n",
    "print(\"Server:\", AIO_SERVER)\n",
    "print(\"Username:\", AIO_USERNAME)\n",
    "print(\"Feed:\", AIO_FEED)\n",
    "\n",
    "# Folder untuk menyimpan foto yang diterima\n",
    "UPLOAD_FOLDER = './uploads'\n",
    "if not os.path.exists(UPLOAD_FOLDER):\n",
    "    os.makedirs(UPLOAD_FOLDER)\n",
    "\n",
    "model = load_model(\"assets/drowsiness_model.h5\")  # grayscale\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "EYE_CLOSED_THRESHOLD = 3  \n",
    "FRAME_COUNT = 0  \n",
    "last_eye_status = \"open\" \n",
    "start_time = None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    # 1. Konversi ke grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2. Menghilangkan noise menggunakan Gaussian Blur\n",
    "    gray_blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # 3. Menajamkan gambar\n",
    "    kernel_sharpening = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "    gray_sharpened = cv2.filter2D(gray_blurred, -1, kernel_sharpening)\n",
    "\n",
    "    # 4. Deteksi wajah\n",
    "    faces = face_cascade.detectMultiScale(gray_sharpened, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    if len(faces) == 0:\n",
    "        return None  # Tidak ada wajah terdeteksi\n",
    "\n",
    "    # 5. Ambil wajah pertama yang terdeteksi\n",
    "    x, y, w, h = faces[0]\n",
    "    face = gray_sharpened[y:y+h, x:x+w]\n",
    "\n",
    "    # 6. Alignment wajah\n",
    "    eyes = face_cascade.detectMultiScale(face)\n",
    "    if len(eyes) >= 2:  # Pastikan ada minimal dua mata terdeteksi\n",
    "        # Ambil dua mata pertama\n",
    "        eye1 = eyes[0]\n",
    "        eye2 = eyes[1]\n",
    "        \n",
    "        # Pastikan eye1 adalah mata kiri dan eye2 mata kanan\n",
    "        if eye1[0] > eye2[0]:\n",
    "            eye1, eye2 = eye2, eye1\n",
    "        \n",
    "        # Koordinat pusat mata\n",
    "        eye1_center = (eye1[0] + eye1[2] // 2, eye1[1] + eye1[3] // 2)\n",
    "        eye2_center = (eye2[0] + eye2[2] // 2, eye2[1] + eye2[3] // 2)\n",
    "\n",
    "        # Sudut rotasi untuk horizontal alignment\n",
    "        dx = eye2_center[0] - eye1_center[0]\n",
    "        dy = eye2_center[1] - eye1_center[1]\n",
    "        angle = np.degrees(np.arctan2(dy, dx))\n",
    "\n",
    "        # Rotasi wajah agar horizontal\n",
    "        M = cv2.getRotationMatrix2D(eye1_center, angle, 1)\n",
    "        face = cv2.warpAffine(face, M, (face.shape[1], face.shape[0]))\n",
    "\n",
    "    # 7. Ekstraksi bagian wajah (mata dan mulut)\n",
    "    face_height, face_width = face.shape\n",
    "    top_cut = int(face_height * 0.3)  # Hapus dahi\n",
    "    bottom_cut = int(face_height * 0.8)  # Fokus pada mata dan mulut\n",
    "    face_cropped = face[top_cut:bottom_cut, :]  # Ekstraksi area wajah yang relevan\n",
    "\n",
    "    # 8. Resize ke dimensi standar\n",
    "    face_resized = cv2.resize(face_cropped, (64, 64))\n",
    "\n",
    "    # 9. Normalisasi pixel\n",
    "    face_normalized = face_resized / 255.0\n",
    "\n",
    "    # 10. Tambahkan dimensi untuk kompatibilitas dengan model\n",
    "    face_final = np.expand_dims(face_normalized, axis=-1)\n",
    "    face_final = np.expand_dims(face_final, axis=0)\n",
    "\n",
    "    return face_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for MQTT connection\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    if rc == 0:\n",
    "        print(\"Connected to MQTT broker\")\n",
    "        client.subscribe(AIO_FEED)\n",
    "    else:\n",
    "        print(f\"Failed to connect, return code {rc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for MQTT message\n",
    "def on_message(client, userdata, msg):\n",
    "    print(f\"Received message from MQTT feed: {msg.topic}, Payload size: {len(msg.payload)} bytes\")\n",
    "\n",
    "    try:\n",
    "        # Jika data dikirim dalam bentuk base64, Anda perlu mendekode\n",
    "        img_data = base64.b64decode(msg.payload)  # Dekode base64 (jika itu yang digunakan)\n",
    "\n",
    "        # Mengubah bytes menjadi gambar menggunakan PIL\n",
    "        image = Image.open(io.BytesIO(img_data))\n",
    "        \n",
    "        # Mengubah gambar menjadi format yang bisa diterima oleh OpenCV\n",
    "        image = np.array(image)\n",
    "\n",
    "        # Pastikan gambar sudah dalam format yang benar\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:  # Memastikan gambar berwarna RGB\n",
    "            print(\"Image decoded successfully\")\n",
    "\n",
    "        else:\n",
    "            print(\"Invalid image format received\")  \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to decode image from payload. Exception: {str(e)}\")\n",
    "\n",
    "    # Save the image locally for debugging\n",
    "    cv2.imwrite(os.path.join(UPLOAD_FOLDER, \"mqtt_image.jpg\"), image)\n",
    "\n",
    "    # Preprocess and predict\n",
    "    processed_image = preprocess_image(image)\n",
    "    if processed_image is None:\n",
    "        print(\"Error: No face detected in the image.\")\n",
    "        return\n",
    "\n",
    "    prediction = model.predict(processed_image)\n",
    "    eye_status = \"closed\" if prediction[0][0] > 0.5 else \"open\"\n",
    "    print(f\"Eye status: {eye_status}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # kode untuk penggunaan buffer\n",
    "\n",
    "# # Daftar untuk menyimpan gambar yang diterima\n",
    "# image_buffer = []\n",
    "\n",
    "# # Callback untuk menerima pesan MQTT\n",
    "# def on_message(client, userdata, msg):\n",
    "#     print(f\"Received message from MQTT feed: {msg.topic}, Payload size: {len(msg.payload)} bytes\")\n",
    "\n",
    "#     try:\n",
    "#         # Jika data dikirim dalam bentuk base64, Anda perlu mendekode\n",
    "#         img_data = base64.b64decode(msg.payload)  # Dekode base64 (jika itu yang digunakan)\n",
    "\n",
    "#         # Mengubah bytes menjadi gambar menggunakan PIL\n",
    "#         image = Image.open(io.BytesIO(img_data))\n",
    "        \n",
    "#         # Mengubah gambar menjadi format yang bisa diterima oleh OpenCV\n",
    "#         image = np.array(image)\n",
    "\n",
    "#         # Pastikan gambar sudah dalam format yang benar\n",
    "#         if len(image.shape) == 3 and image.shape[2] == 3:  # Memastikan gambar berwarna RGB\n",
    "#             print(\"Image decoded successfully\")\n",
    "#         else:\n",
    "#             print(\"Invalid image format received\")  \n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: Failed to decode image from payload. Exception: {str(e)}\")\n",
    "#         return\n",
    "\n",
    "#     # Menyimpan gambar ke dalam buffer untuk analisis lebih lanjut\n",
    "#     image_buffer.append(image)\n",
    "\n",
    "#     # Jika sudah ada 3 gambar dalam buffer, lakukan analisis\n",
    "#     if len(image_buffer) >= 3:\n",
    "#         # Analisis status pengemudi berdasarkan 3 gambar\n",
    "#         eye_status_count = {\"open\": 0, \"closed\": 0}\n",
    "#         yawn_status_count = {\"open\": 0, \"closed\": 0}\n",
    "\n",
    "#         # Proses ketiga gambar\n",
    "#         for img in image_buffer:\n",
    "#             processed_image = preprocess_image(img)\n",
    "#             if processed_image is None:\n",
    "#                 print(\"Error: No face detected in the image.\")\n",
    "#                 continue\n",
    "\n",
    "#             prediction = model.predict(processed_image)\n",
    "#             eye_status = \"closed\" if prediction[0][0] > 0.5 else \"open\"\n",
    "#             print(f\"Eye status: {eye_status}\")\n",
    "\n",
    "#             # Cek status mulut (yawn detection) jika model mendeteksi mulut terbuka\n",
    "#             if is_yawning(processed_image):  # Anda bisa menambahkan fungsi deteksi mulut terbuka di sini\n",
    "#                 yawn_status = \"open\"  # Mulut terbuka menandakan menguap\n",
    "#             else:\n",
    "#                 yawn_status = \"closed\"  # Mulut tertutup menandakan tidak menguap\n",
    "            \n",
    "#             # Hitung frekuensi status mata dan mulut\n",
    "#             if eye_status == \"open\":\n",
    "#                 eye_status_count[\"open\"] += 1\n",
    "#             else:\n",
    "#                 eye_status_count[\"closed\"] += 1\n",
    "\n",
    "#             if yawn_status == \"open\":\n",
    "#                 yawn_status_count[\"open\"] += 1\n",
    "#             else:\n",
    "#                 yawn_status_count[\"closed\"] += 1\n",
    "\n",
    "#         # Tentukan status pengemudi berdasarkan analisis tiga gambar\n",
    "#         if eye_status_count[\"closed\"] == 3:\n",
    "#             print(\"Pengemudi mengantuk - Mata tertutup di ketiga gambar.\")\n",
    "#             send_sleep_status(\"mengantuk\")\n",
    "#         elif yawn_status_count[\"open\"] == 3:\n",
    "#             print(\"Pengemudi menguap - Mulut terbuka di ketiga gambar.\")\n",
    "#             send_sleep_status(\"menguap\")\n",
    "#         elif eye_status_count[\"closed\"] > 0 and yawn_status_count[\"open\"] > 0:\n",
    "#             print(\"Pengemudi segar - Tidak semua gambar menunjukkan mata tertutup/mulut terbuka.\")\n",
    "#             send_sleep_status(\"segar\")\n",
    "#         elif eye_status_count[\"open\"] == 3:\n",
    "#             print(\"Pengemudi tidak mengantuk - Mata terbuka di ketiga gambar.\")\n",
    "#             send_sleep_status(\"tidak mengantuk\")\n",
    "\n",
    "#         # Reset buffer untuk gambar berikutnya\n",
    "#         image_buffer.clear()\n",
    "\n",
    "# # Fungsi untuk mengirim status ke sistem (misalnya menggunakan MQTT atau API)\n",
    "# def send_sleep_status(status):\n",
    "#     print(f\"Sending status: {status}\")\n",
    "#     # Kode untuk mengirim status (misalnya melalui MQTT atau API)\n",
    "#     # mqtt_client.publish(\"your_topic\", status)\n",
    "\n",
    "# # Fungsi tambahan untuk deteksi mulut terbuka (yawn)\n",
    "# def is_yawning(image):\n",
    "#     # Implementasikan deteksi mulut terbuka pada gambar (gunakan model atau algoritma lainnya)\n",
    "#     # Ini adalah contoh fungsi kosong, Anda dapat menyesuaikannya dengan kebutuhan Anda.\n",
    "#     return False  # Ganti dengan implementasi sebenarnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MQTT Client Setup\n",
    "mqtt_client = Client()\n",
    "mqtt_client.username_pw_set(AIO_USERNAME, AIO_KEY)\n",
    "mqtt_client.on_connect = on_connect\n",
    "mqtt_client.on_message = on_message\n",
    "\n",
    "mqtt_client.connect(AIO_SERVER, 1883)\n",
    "mqtt_client.loop_start()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return \"Server is running and connected to MQTT feed.\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_frame(current_eye_status):\n",
    "\n",
    "#     global FRAME_COUNT, last_eye_status, start_time\n",
    "\n",
    "#     if current_eye_status == \"closed\":\n",
    "#         if last_eye_status == \"closed\":\n",
    "#             FRAME_COUNT += 3\n",
    "#         else:\n",
    "#             FRAME_COUNT = 3\n",
    "#             start_time = time.time() \n",
    "#     else:\n",
    "#         FRAME_COUNT = 0\n",
    "#         start_time = None \n",
    "\n",
    "#     last_eye_status = current_eye_status\n",
    "\n",
    "#     if FRAME_COUNT >= EYE_CLOSED_THRESHOLD and (time.time() - start_time >= 3.5):\n",
    "#         return \"sleepy\"\n",
    "#     else:\n",
    "#         return \"not sleepy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route('/process_image', methods=['POST'])\n",
    "# def process_image():\n",
    "#     global FRAME_COUNT, last_eye_status, start_time\n",
    "\n",
    "#     # Mengambil file gambar yang diupload\n",
    "#     if 'image' not in request.files:\n",
    "#         return jsonify({\"error\": \"No image file provided\"}), 400\n",
    "\n",
    "#     file = request.files['image']\n",
    "#     image = Image.open(io.BytesIO(file.read()))\n",
    "\n",
    "#     image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     processed_image = preprocess_image(image)\n",
    "\n",
    "#     if processed_image is None:\n",
    "#         return jsonify({\"error\": \"No face detected in the image\"}), 400\n",
    "\n",
    "#     # Misalkan Anda menggunakan model yang sudah dilatih\n",
    "#     prediction = model.predict(processed_image)\n",
    "\n",
    "#     if prediction[0][0] > 0.5:\n",
    "#         current_eye_status = \"closed\"\n",
    "#     else:\n",
    "#         current_eye_status = \"open\"\n",
    "\n",
    "#     result = process_frame(current_eye_status)\n",
    "\n",
    "#     return jsonify({\"result\": result})\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(host='0.0.0.0', port=5000)\n",
    "\n",
    "# @app.route('/')\n",
    "# def index():\n",
    "#     return \"Server is running and ready to accept images.\"\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(host='0.0.0.0', port=5000)  # Jalankan server di port 5000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
