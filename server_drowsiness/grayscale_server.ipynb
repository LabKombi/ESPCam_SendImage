{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "\n",
    "\n",
    "# Import konfigurasi dari file config.py\n",
    "from config_aio import AIO_SERVER, AIO_USERNAME, AIO_KEY, AIO_FEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inisialisasi Firebase\n",
    "# cred = credentials.Certificate('firebase_sdk_admin_led_switch.json')\n",
    "# firebase_admin.initialize_app(cred, {\n",
    "#     'databaseURL': 'https://led-switch-6c690-default-rtdb.firebaseio.com'  # Ganti dengan URL Realtime Database Anda\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "# Adafruit IO Configuration\n",
    "\n",
    "# Gunakan konfigurasi dalam kode Anda\n",
    "print(\"Server:\", AIO_SERVER)\n",
    "print(\"Username:\", AIO_USERNAME)\n",
    "print(\"Feed:\", AIO_FEED)\n",
    "\n",
    "# Folder untuk menyimpan foto yang diterima\n",
    "UPLOAD_FOLDER = './uploads'\n",
    "if not os.path.exists(UPLOAD_FOLDER):\n",
    "    os.makedirs(UPLOAD_FOLDER)\n",
    "\n",
    "model = load_model(\"../model/old_grayscale_model.h5\")  # grayscale\n",
    "# model = load_model(\"drowsiness_detection_model_after.h5\") # RGB\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "EYE_CLOSED_THRESHOLD = 3  \n",
    "FRAME_COUNT = 0  \n",
    "last_eye_status = \"open\" \n",
    "start_time = None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_image(image):\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "#     if len(faces) == 0:\n",
    "#         return None\n",
    "\n",
    "#     x, y, w, h = faces[0]\n",
    "#     face = gray[y:y+h, x:x+w]\n",
    "\n",
    "#     face_resized = cv2.resize(face, (64, 64))\n",
    "\n",
    "#     face_normalized = face_resized / 255.0\n",
    "    \n",
    "#     face_final = np.expand_dims(face_normalized, axis=-1)\n",
    "#     face_final = np.expand_dims(face_final, axis=0) \n",
    "#     return face_final\n",
    "\n",
    "def preprocess_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    x, y, w, h = faces[0]\n",
    "    face = gray[y:y+h, x:x+w]\n",
    "    face_resized = cv2.resize(face, (64, 64))\n",
    "    face_normalized = face_resized / 255.0\n",
    "    face_final = np.expand_dims(face_normalized, axis=-1)\n",
    "    face_final = np.expand_dims(face_final, axis=0)\n",
    "    return face_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for MQTT connection\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    if rc == 0:\n",
    "        print(\"Connected to MQTT broker\")\n",
    "        client.subscribe(AIO_FEED)\n",
    "    else:\n",
    "        print(f\"Failed to connect, return code {rc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for MQTT message\n",
    "def on_message(client, userdata, msg):\n",
    "    print(f\"Received message from MQTT feed: {msg.topic}, Payload size: {len(msg.payload)} bytes\")\n",
    "\n",
    "    try:\n",
    "        # Jika data dikirim dalam bentuk base64, Anda perlu mendekode\n",
    "        img_data = base64.b64decode(msg.payload)  # Dekode base64 (jika itu yang digunakan)\n",
    "\n",
    "        # Mengubah bytes menjadi gambar menggunakan PIL\n",
    "        image = Image.open(io.BytesIO(img_data))\n",
    "        \n",
    "        # Mengubah gambar menjadi format yang bisa diterima oleh OpenCV\n",
    "        image = np.array(image)\n",
    "\n",
    "        # Pastikan gambar sudah dalam format yang benar\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:  # Memastikan gambar berwarna RGB\n",
    "            print(\"Image decoded successfully\")\n",
    "\n",
    "        else:\n",
    "            print(\"Invalid image format received\")  \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to decode image from payload. Exception: {str(e)}\")\n",
    "\n",
    "    # Save the image locally for debugging\n",
    "    cv2.imwrite(os.path.join(UPLOAD_FOLDER, \"mqtt_image.jpg\"), image)\n",
    "\n",
    "    # Preprocess and predict\n",
    "    processed_image = preprocess_image(image)\n",
    "    if processed_image is None:\n",
    "        print(\"Error: No face detected in the image.\")\n",
    "        return\n",
    "\n",
    "    prediction = model.predict(processed_image)\n",
    "    eye_status = \"closed\" if prediction[0][0] > 0.5 else \"open\"\n",
    "    print(f\"Eye status: {eye_status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eye status: open\n",
      "Received message from MQTT feed: Only_B/feeds/photo, Payload size: 7204 bytes\n",
      "Image decoded successfully\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Eye status: open\n",
      "Received message from MQTT feed: Only_B/feeds/photo, Payload size: 6392 bytes\n",
      "Image decoded successfully\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Eye status: open\n",
      "Received message from MQTT feed: Only_B/feeds/photo, Payload size: 6632 bytes\n",
      "Image decoded successfully\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "Eye status: open\n",
      "Received message from MQTT feed: Only_B/feeds/photo, Payload size: 6620 bytes\n",
      "Image decoded successfully\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "Eye status: closed\n",
      "Received message from MQTT feed: Only_B/feeds/photo, Payload size: 6152 bytes\n",
      "Image decoded successfully\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "Eye status: closed\n",
      "Received message from MQTT feed: Only_B/feeds/photo, Payload size: 6336 bytes\n",
      "Image decoded successfully\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Eye status: closed\n",
      "Received message from MQTT feed: Only_B/feeds/photo, Payload size: 6496 bytes\n",
      "Image decoded successfully\n",
      "Error: No face detected in the image.\n",
      "Received message from MQTT feed: Only_B/feeds/photo, Payload size: 6476 bytes\n",
      "Image decoded successfully\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Eye status: open\n",
      "Received message from MQTT feed: Only_B/feeds/photo, Payload size: 6580 bytes\n",
      "Image decoded successfully\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "Eye status: open\n",
      "Received message from MQTT feed: Only_B/feeds/photo, Payload size: 6580 bytes\n",
      "Image decoded successfully\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "Eye status: closed\n"
     ]
    }
   ],
   "source": [
    "# MQTT Client Setup\n",
    "mqtt_client = Client()\n",
    "mqtt_client.username_pw_set(AIO_USERNAME, AIO_KEY)\n",
    "mqtt_client.on_connect = on_connect\n",
    "mqtt_client.on_message = on_message\n",
    "\n",
    "mqtt_client.connect(AIO_SERVER, 1883)\n",
    "mqtt_client.loop_start()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return \"Server is running and connected to MQTT feed.\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_frame(current_eye_status):\n",
    "\n",
    "#     global FRAME_COUNT, last_eye_status, start_time\n",
    "\n",
    "#     if current_eye_status == \"closed\":\n",
    "#         if last_eye_status == \"closed\":\n",
    "#             FRAME_COUNT += 3\n",
    "#         else:\n",
    "#             FRAME_COUNT = 3\n",
    "#             start_time = time.time() \n",
    "#     else:\n",
    "#         FRAME_COUNT = 0\n",
    "#         start_time = None \n",
    "\n",
    "#     last_eye_status = current_eye_status\n",
    "\n",
    "#     if FRAME_COUNT >= EYE_CLOSED_THRESHOLD and (time.time() - start_time >= 3.5):\n",
    "#         return \"sleepy\"\n",
    "#     else:\n",
    "#         return \"not sleepy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route('/process_image', methods=['POST'])\n",
    "# def process_image():\n",
    "#     global FRAME_COUNT, last_eye_status, start_time\n",
    "\n",
    "#     # Mengambil file gambar yang diupload\n",
    "#     if 'image' not in request.files:\n",
    "#         return jsonify({\"error\": \"No image file provided\"}), 400\n",
    "\n",
    "#     file = request.files['image']\n",
    "#     image = Image.open(io.BytesIO(file.read()))\n",
    "\n",
    "#     image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     processed_image = preprocess_image(image)\n",
    "\n",
    "#     if processed_image is None:\n",
    "#         return jsonify({\"error\": \"No face detected in the image\"}), 400\n",
    "\n",
    "#     # Misalkan Anda menggunakan model yang sudah dilatih\n",
    "#     prediction = model.predict(processed_image)\n",
    "\n",
    "#     if prediction[0][0] > 0.5:\n",
    "#         current_eye_status = \"closed\"\n",
    "#     else:\n",
    "#         current_eye_status = \"open\"\n",
    "\n",
    "#     result = process_frame(current_eye_status)\n",
    "\n",
    "#     return jsonify({\"result\": result})\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(host='0.0.0.0', port=5000)\n",
    "\n",
    "# @app.route('/')\n",
    "# def index():\n",
    "#     return \"Server is running and ready to accept images.\"\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(host='0.0.0.0', port=5000)  # Jalankan server di port 5000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
